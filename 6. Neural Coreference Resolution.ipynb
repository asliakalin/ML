{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW_6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asliakalin/NLP/blob/master/6.%20Neural%20Coreference%20Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mh8KqXb0yR8"
      },
      "source": [
        "# Homework 6: Neural Coreference Resolution\n",
        "\n",
        "**Due April 20, 2020 at 11:59pm**\n",
        "\n",
        "In this homework,  you will be implementing parts of a Pytorch implementation for neural coreference resolution, inspired by [Lee et al.(2017), “End-to-end Neural Coreference Resolution” (EMNLP)](https://arxiv.org/pdf/1707.07045.pdf). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UqglTYOZ9jd"
      },
      "source": [
        "### REMEMBER TO UPLOAD THE DATASET!\n",
        "Click the Files icon > Upload > Upload train.conll and dev.conll that you have downloaded from bCourses: Files/HW_6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpxETEnm1c0h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7u1xOC_zcEG"
      },
      "source": [
        "import sys, re\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Wm71YOajw0"
      },
      "source": [
        "We noticed that running this on CPU is faster than running on GPU. Thus, we will default to running on CPU. However, feel free to change it to GPU if you wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5qiaj6zzfSN",
        "outputId": "03f7f001-1eeb-48d8-d757-54db072e6e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "print(\"Running on {}\".format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qTmWIJq56IA"
      },
      "source": [
        "### Download and process data\n",
        "Note: You do **not** have to modify this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDP_KFPo7N12",
        "outputId": "d8db4e99-7fe1-4730-ebe0-64d991bce90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-29 05:33:30--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-04-29 05:33:30--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-04-29 05:33:31--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.03MB/s    in 6m 29s  \n",
            "\n",
            "2020-04-29 05:40:00 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRDDk-tu-EfJ"
      },
      "source": [
        "def read_conll(filename):\n",
        "\n",
        "  docid=None\n",
        "  partID=None\n",
        "\n",
        "  # collection\n",
        "  all_sents=[]\n",
        "  all_ents=[]\n",
        "\n",
        "  # for one doc\n",
        "  all_doc_sents=[]\n",
        "  all_doc_ents=[]\n",
        "\n",
        "  # for one sentence\n",
        "  sent=[]\n",
        "  ents=[]\n",
        "\n",
        "  named_ents=[]\n",
        "  cur_tid=0\n",
        "  open_count=0\n",
        "\n",
        "  global_eid=0\n",
        "  doc_eid_to_global_eid={}\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "      if line.startswith(\"#begin document\"):\n",
        "\n",
        "        all_doc_ents=[]\n",
        "        all_doc_sents=[]\n",
        "\n",
        "        open_ents={}\n",
        "        open_named_ents={}\n",
        "\n",
        "        docid=None\n",
        "        matcher=re.match(\"#begin document \\((.*)\\); part (.*)$\", line.rstrip())\n",
        "        if matcher != None:\n",
        "          docid=matcher.group(1)\n",
        "          partID=matcher.group(2)\n",
        "\n",
        "      elif line.startswith(\"#end document\"):\n",
        "\n",
        "        all_sents.append(all_doc_sents)\n",
        "        all_ents.append(all_doc_ents)\n",
        "\n",
        "        \n",
        "      else:\n",
        "\n",
        "        parts=re.split(\"\\s+\", line.rstrip())\n",
        "\n",
        "        # sentence boundary\n",
        "        if len(parts) < 2:\n",
        "    \n",
        "          all_doc_sents.append(sent)\n",
        "\n",
        "          ents=sorted(ents, key=lambda x: (x[0], x[1]))\n",
        "\n",
        "          all_doc_ents.append(ents)\n",
        "\n",
        "          sent=[]\n",
        "          ents=[]\n",
        "\n",
        "          cur_tid=0\n",
        "\n",
        "          continue\n",
        "\n",
        "        tid=cur_tid\n",
        "        token=parts[3]\n",
        "        cur_tid+=1\n",
        "\n",
        "        identifier=\"%s.%s\" % (docid, partID)\n",
        "\n",
        "        coref=parts[-1].split(\"|\")\n",
        "\n",
        "        for c in coref:\n",
        "          if c.startswith(\"(\") and c.endswith(\")\"):\n",
        "            c=re.sub(\"\\(\", \"\", c)\n",
        "            c=int(re.sub(\"\\)\", \"\", c))\n",
        "\n",
        "            if (identifier, c) not in doc_eid_to_global_eid:\n",
        "              doc_eid_to_global_eid[(identifier, c)]=len(doc_eid_to_global_eid)\n",
        "\n",
        "            ents.append((tid, tid, doc_eid_to_global_eid[(identifier, c)], identifier))\n",
        "\n",
        "          elif c.startswith(\"(\"):\n",
        "            c=int(re.sub(\"\\(\", \"\", c))\n",
        "\n",
        "            if c not in open_ents:\n",
        "              open_ents[c]=[]\n",
        "            open_ents[c].append(tid)\n",
        "            open_count+=1\n",
        "\n",
        "          elif c.endswith(\")\"):\n",
        "            c=int(re.sub(\"\\)\", \"\", c))\n",
        "\n",
        "            assert c in open_ents\n",
        "\n",
        "            start_tid=open_ents[c].pop()\n",
        "            open_count-=1\n",
        "\n",
        "            if (identifier, c) not in doc_eid_to_global_eid:\n",
        "              doc_eid_to_global_eid[(identifier, c)]=len(doc_eid_to_global_eid)\n",
        "\n",
        "            ents.append((start_tid, tid, doc_eid_to_global_eid[(identifier, c)], identifier))\n",
        "\n",
        "        sent.append(token)\n",
        "\n",
        "  return all_sents, all_ents\n",
        "\n",
        "def load_embeddings(filename, vocab_size):\n",
        "  # 0 idx is for padding\n",
        "  # 1 idx is for unknown words\n",
        "\n",
        "  # get the embedding size from the first embedding\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    word_embedding_dim=len(file.readline().split(\" \"))-1\n",
        "\n",
        "  vocab={\"[PAD]\":0, \"[UNK]\":1}\n",
        "\n",
        "  print(\"word_embedding_dim:\", word_embedding_dim)\n",
        "\n",
        "  embeddings=np.zeros((vocab_size, word_embedding_dim))\n",
        "\n",
        "  with open(filename, encoding=\"utf-8\") as file:\n",
        "    for idx,line in enumerate(file):\n",
        "\n",
        "      if idx + 2 >= vocab_size:\n",
        "        break\n",
        "\n",
        "      cols=line.rstrip().split(\" \")\n",
        "      val=np.array(cols[1:])\n",
        "      word=cols[0]\n",
        "      embeddings[idx+2]=val\n",
        "      vocab[word]=idx+2\n",
        "\n",
        "  return torch.FloatTensor(embeddings), vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F17zKOXO6Cap",
        "outputId": "983ca679-eb1c-489d-84f4-c8197b0c5919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embeddingFile = \"glove.6B.50d.txt\"\n",
        "trainFile = \"train.conll\"\n",
        "devFile = \"dev.conll\"\n",
        "\n",
        "all_sents, all_ents=read_conll(trainFile)\t\n",
        "dev_all_sents, dev_all_ents=read_conll(devFile)\n",
        "\n",
        "embeddings, vocab=load_embeddings(embeddingFile, 50000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_embedding_dim: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeMhT6UN1eP5"
      },
      "source": [
        "### **Part 1. Implement B3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YshAEm0xd8NL"
      },
      "source": [
        "In this part, you’ll implement the B3 coreference metric as discussed in class without importing external libraries. \n",
        "\n",
        "Recall the definition: \n",
        "$B^{_{precision}^{3}} = \\frac{1}{n}\\sum_{i}^{n} \\frac{\\left |Gold_{i} \\cap  System_{i} \\right |}{\\left | System_{i} \\right |}$\n",
        "$B^{_{recall}^{3}} = \\frac{1}{n}\\sum_{i}^{n} \\frac{\\left |Gold_{i} \\cap  System_{i} \\right |}{\\left | Gold_{i} \\right |}$\n",
        "\n",
        "You should be able to pass the sanity check b3_test() after implementing it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpEJaiqez-bd"
      },
      "source": [
        "def b3(gold, system):\n",
        "  \"\"\" Calculate B3 metrics given the gold and system output\n",
        "    Args:\n",
        "        gold  : A dictionary that contains true refereneces. The \n",
        "        key is a tuple, (docid, absolute_start_idx, absolute_end_idx)representing a target to be predicted; \n",
        "        value is the true reference entity id.\n",
        "\n",
        "        system: A dictionary that contains predicted referenece. \n",
        "        key in gold and system should be identical; \n",
        "        value is the predicted entity generated by the model.\n",
        "\n",
        "    Returns:\n",
        "        precision, recall, F(following the formula above)\n",
        "\n",
        "    \"\"\"\n",
        "  precision=0.\n",
        "  recall=0.\n",
        "  F = 0.\n",
        "  #####\n",
        "  # Your code here\n",
        "  #####\n",
        "  common_gold_links = {}\n",
        "  common_sys_links = {}\n",
        "  for k in system.keys():\n",
        "    v = system[k]\n",
        "    if v in common_sys_links:\n",
        "      common_sys_links[v] += [k]\n",
        "    else:\n",
        "      common_sys_links[v] = [k]\n",
        "\n",
        "  for k in gold.keys():\n",
        "    v = gold[k]\n",
        "    if v in common_gold_links:\n",
        "      common_gold_links[v] += [k]\n",
        "    else:\n",
        "      common_gold_links[v] = [k]\n",
        "  #print(common_gold_links)\n",
        "\n",
        "  for item in system.keys():\n",
        "    goldkey = gold[item]\n",
        "    syskey = system[item] \n",
        "    goldchain = common_gold_links[goldkey]\n",
        "    syschain = common_sys_links[syskey]\n",
        "    #print(goldchain, syschain)\n",
        "\n",
        "    precision += len(set(goldchain).intersection(set(syschain)))/len(set(syschain))\n",
        "    recall += len(set(goldchain).intersection(set(syschain)))/len(set(goldchain))\n",
        "\n",
        "  precision = precision/len(gold.keys())\n",
        "  recall = recall/len(gold.keys())\n",
        "  F = 2 * (recall * precision) / (recall + precision)\n",
        "    \n",
        "  return precision, recall, F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eybIuitz3Co",
        "outputId": "b1fea70c-2637-4069-e37d-2983a615e37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "def b3_test():\n",
        "  gold={\"a1\":1, \"a2\": 2, \"a3\": 1, \"a4\":1, \"a5\": 3, \"a6\":3, \"a7\":2, \"a8\":2, \"a9\":1, \"a10\":1}\n",
        "  system={\"a1\":5, \"a2\": 6, \"a3\": 6, \"a4\":6, \"a5\": 7, \"a6\":7, \"a7\":5, \"a8\":5, \"a9\":5, \"a10\":8}\n",
        "\n",
        "  precision, recall, F=b3(gold, system)\n",
        "  print(\"P: %.3f, R: %.3f, F: %.3f\" % (precision, recall, F))\n",
        "\n",
        "  assert abs(precision-0.667) < 0.001\n",
        "  assert abs(recall-0.547) < 0.001\n",
        "  assert abs(F-0.601) < 0.001\n",
        "  \n",
        "  print (\"B3 sanity check passed\")\n",
        "b3_test()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P: 0.667, R: 0.547, F: 0.601\n",
            "B3 sanity check passed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNFaD5IO_P3F"
      },
      "source": [
        "### **Part 2. Neural coref**\n",
        "In part 2, the skeleton code for mention-ranking model is provided to you, you will not need to change any code until Part 2.1 begins. The following section provides the Mention class which is used to store relavant information about a mention and the BasicCorefModel. You will, at the very least, need to carefully read these two classes and understand the information stored in Mention and the structure of the model to complete this homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dVP6JsQzghb"
      },
      "source": [
        "class Mention():\n",
        "\n",
        "  \"\"\"\n",
        "  An object to contain information about each mention\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, mention_id, docid, absolute_start_idx, absolute_end_idx, sentence_start_idx, sentence_end_idx, sentence, vocab):\n",
        "    self.docid=docid\n",
        "\n",
        "    # mention id (globally unique within one file, but not across different train and test files)\n",
        "    self.mention_id=mention_id\n",
        "    # the token index of the mention start position, measured from the beginning of the document\n",
        "    self.absolute_start_idx=absolute_start_idx\n",
        "    # the token index of the mention end position, measured from the beginning of the document\n",
        "    self.absolute_end_idx=absolute_end_idx\n",
        "    # the token index of the mention start position, measured from the beginning of the sentence\n",
        "    self.sentence_start_idx=sentence_start_idx\n",
        "    # the token index of the mention end position, measured from the beginning of the sentence\n",
        "    self.sentence_end_idx=sentence_end_idx\n",
        "    # a list of tokens for all the words in the mention's sentence\n",
        "    self.sentence=sentence\n",
        "    # a list of tokens ids for all the words in the mention's sentence\n",
        "    self.sentence_ids=[]\n",
        "    self.sentence_length=len(sentence)\n",
        "\n",
        "    for word in sentence:\n",
        "      word=word.lower()\n",
        "      self.sentence_ids.append(vocab[word] if word in vocab else vocab[\"[UNK]\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ3B8CU4AGvc"
      },
      "source": [
        "def convert_data_to_training_instances(all_sents, all_ents, vocab):\n",
        "  X=[]\n",
        "  Y=[]\n",
        "  M=[]\n",
        "\n",
        "  global_id=0\n",
        "  truth={}\n",
        "\n",
        "  for doc_idx, doc_ent in enumerate(all_ents):\n",
        "    current_token_position=0\n",
        "    existing_mentions=[]\n",
        "    for sent_idx, mention_list in enumerate(doc_ent):\n",
        "      sent=all_sents[doc_idx][sent_idx]\n",
        "\n",
        "      for mention_idx, mention in enumerate(mention_list):\n",
        "        start_sent_idx, end_sent_idx, entity_id, identifier=mention\n",
        "        mention=Mention(global_id, identifier, current_token_position+start_sent_idx, current_token_position+end_sent_idx, start_sent_idx, end_sent_idx, sent, vocab)\n",
        "        M.append(mention)\n",
        "        truth[global_id]=entity_id\n",
        "        global_id+=1\n",
        "        x=[]\n",
        "        y=[]\n",
        "        for aidx, antecedent in enumerate(existing_mentions):\n",
        "          x.append(antecedent)\n",
        "          if truth[antecedent.mention_id] == truth[mention.mention_id]:\n",
        "            y.append(aidx)\n",
        "\n",
        "        X.append(x)\n",
        "        Y.append(torch.LongTensor(y).to(device))\n",
        "        existing_mentions.append(mention)\n",
        "      current_token_position+=len(sent)\n",
        "\n",
        "  return X, Y, M, truth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oPEwL-wQfyf"
      },
      "source": [
        "######### HELPER FUNCTION FOR TRAINING STARTS #########\n",
        "#########  DONT'T EDIT THIS SECTION OF CODE   #########\n",
        "def forward_predict(batch_x, batch_m, scoring_function):\n",
        "\n",
        "  this_batch_size=len(batch_x)\n",
        "  num_ants=len(batch_x[0])\n",
        "\n",
        "  # if this batch has no antecedents, then it must start a new entity\n",
        "  if num_ants == 0:\n",
        "    return torch.LongTensor([0]*this_batch_size)\n",
        "  \n",
        "  # get predictions\n",
        "  preds=scoring_function(batch_x, batch_m)\n",
        "\n",
        "  # \n",
        "  arg_sorts=torch.argsort(preds, descending=True, dim=1)\n",
        "  tops=arg_sorts[:,0]\n",
        "\n",
        "  return tops\n",
        "\n",
        "\n",
        "def forward_train(batch_x, batch_y, batch_m, scoring_function):\n",
        "\n",
        "  num_batch=len(batch_x)\n",
        "  num_ants=len(batch_x[0])\n",
        "\n",
        "  # if this batch has no candidate antecedents, then each mention must start a new entity so there is only only choice we could make (hence no loss)\n",
        "  if num_ants == 0:\n",
        "    return None\n",
        "\n",
        "  preds=scoring_function(batch_x, batch_m)\n",
        "  preds_sum=torch.logsumexp(preds, 1)\n",
        "\n",
        "  running_loss=None\n",
        "\n",
        "\n",
        "  for i in range(num_batch):\n",
        "\n",
        "    # optimize marginal log-likelihood of true antecedents\n",
        "    if batch_y[i].nelement() == 0:\n",
        "      golds_sum=0.\n",
        "    else:\n",
        "      golds=torch.index_select(preds[i], 0, batch_y[i])\n",
        "      golds_sum=torch.logsumexp(golds, 0)\n",
        "\n",
        "    diff=preds_sum[i]-golds_sum\n",
        "\n",
        "    running_loss = diff if running_loss is None else running_loss + diff\n",
        "\n",
        "  return running_loss\n",
        "\n",
        "def get_batches(X, Y, M, batchsize):\n",
        "  sizes={}\n",
        "  for i in range(len(M)):\n",
        "    size=len(X[i])\n",
        "    if size not in sizes:\n",
        "      sizes[size]=[]\n",
        "    sizes[size].append((X[i], Y[i], M[i]))\n",
        "\n",
        "  batches=[]\n",
        "\n",
        "  for size in sizes:\n",
        "    i=0\n",
        "    while (i < len(sizes[size])):\n",
        "\n",
        "      data=sizes[size][i:i+batchsize]\n",
        "      batch_x=[]\n",
        "      batch_y=[]\n",
        "      batch_m=[]\n",
        "      for x, y, m in data:\n",
        "        batch_x.append(x)\n",
        "        batch_y.append(y)\n",
        "        batch_m.append(m)\n",
        "\n",
        "      batches.append((batch_x, batch_y, batch_m))\n",
        "      i+=batchsize\n",
        "\n",
        "  return batches\n",
        "\n",
        "\n",
        "def train(X, Y, M, train_gold, test_X, test_Y, test_M, test_gold, model):\n",
        "\n",
        "  batches=get_batches(X, Y, M, 32)\n",
        "  test_batches=get_batches(test_X, test_Y, test_M, 32)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "  for epoch in range(10):\n",
        "\n",
        "    model.train()\n",
        "    # train\n",
        "    bigloss=0.\n",
        "    for batch_x, batch_y, batch_m in batches:\n",
        "      model.zero_grad()\n",
        "      loss=forward_train(batch_x, batch_y, batch_m, model.scorer)\n",
        "      if loss is not None:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        bigloss+=loss\n",
        "\n",
        "    # evaluate\n",
        "    model.eval()\n",
        "\n",
        "    gold={}\n",
        "    predicted={}\n",
        "\n",
        "    eid=0\n",
        "    tot=0\n",
        "\n",
        "    for batch_x, batch_y, batch_m in test_batches:\n",
        "      predictions=forward_predict(batch_x, batch_m, model.scorer)\n",
        "\n",
        "      for idx, mention in enumerate(batch_m):\n",
        "\n",
        "        gold[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=test_gold[mention.mention_id]\n",
        "        prediction=predictions[idx]\n",
        "        tot+=1\n",
        "      \n",
        "        # prediction is to start a new entity\n",
        "        if prediction >= len(batch_x[idx]):\n",
        "          predicted[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=eid\n",
        "          eid+=1\n",
        "\n",
        "        # prediction is to link to a previous mention\n",
        "        else:\n",
        "\n",
        "          best_antecedent=batch_x[idx][prediction]\n",
        "          predicted_entity_id=predicted[best_antecedent.docid, best_antecedent.absolute_start_idx, best_antecedent.absolute_end_idx]\n",
        "          predicted[mention.docid, mention.absolute_start_idx, mention.absolute_end_idx]=predicted_entity_id\n",
        "\n",
        "    P, R, F=b3(gold, predicted)\n",
        "    print(\"loss: %.3f, B3 F: %.3f, unique entities: %s, num mentions: %s\" % (bigloss, F, eid, tot))\n",
        "\n",
        "def set_seed(seed):\n",
        "  \"\"\"\n",
        "  Sets random seeds and sets model in deterministic\n",
        "  training mode. Ensures reproducible results\n",
        "  \"\"\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(seed)\n",
        "######### HELPER FUNCTION FOR TRAINING ENDS #########\n",
        "#########  DONT'T EDIT THIS SECTION OF CODE   #########"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmOCaewzj3e"
      },
      "source": [
        "class BasicCorefModel(nn.Module):\n",
        "\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(BasicCorefModel, self).__init__()\n",
        "\t\tself.vocab=vocab\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\t\t_, embedding_size=embeddings.shape\n",
        "\t\tself.hidden_dim=50\n",
        "\n",
        "\t\tself.input_size=2 * embedding_size\n",
        "\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh=nn.Tanh()\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tthis_batch_size=len(batch_x)\n",
        "\t\tnum_ants=len(batch_x[0])\n",
        "\n",
        "\t\t# get representations for mentions\n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m):\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size]\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size].\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, (embedding_size + embedding_size)]\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings], 2)\n",
        "\t\t\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\n",
        "\t\t# Let's fix the score for starting a new entity to be 0; all of the other scores for candidate antecedents will end up \n",
        "\t\t# being relative to that.\n",
        "\n",
        "\t\t# [this_batch_size, 1]\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\n",
        "\t\treturn preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7_H0_p-bHhp"
      },
      "source": [
        "Now, everything is set up to run the BasicCorefModel. Let's run the cell below to train the model and look at the result of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnvgFWdPblQ_",
        "outputId": "15652007-4e2a-4432-ba6f-b4b55d339cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "X, Y, M, train_truth=convert_data_to_training_instances(all_sents, all_ents, vocab)\n",
        "dev_X, dev_Y, dev_M, dev_truth=convert_data_to_training_instances(dev_all_sents, dev_all_ents, vocab)\n",
        "set_seed(159)\n",
        "model=BasicCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "print (\"Training BasicCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training BasicCorefModel\n",
            "loss: 41274.820, B3 F: 0.764, unique entities: 29578, num mentions: 29597\n",
            "loss: 33196.117, B3 F: 0.764, unique entities: 29569, num mentions: 29597\n",
            "loss: 29578.078, B3 F: 0.765, unique entities: 29323, num mentions: 29597\n",
            "loss: 27773.996, B3 F: 0.771, unique entities: 28797, num mentions: 29597\n",
            "loss: 26788.643, B3 F: 0.779, unique entities: 27948, num mentions: 29597\n",
            "loss: 26151.432, B3 F: 0.782, unique entities: 27427, num mentions: 29597\n",
            "loss: 25682.389, B3 F: 0.783, unique entities: 27372, num mentions: 29597\n",
            "loss: 25319.137, B3 F: 0.786, unique entities: 26932, num mentions: 29597\n",
            "loss: 25024.688, B3 F: 0.789, unique entities: 26854, num mentions: 29597\n",
            "loss: 24776.920, B3 F: 0.793, unique entities: 26450, num mentions: 29597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi-A_Ho9P3bl"
      },
      "source": [
        "### **Part 2.1 Incorporate distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "718TVDuESx4G"
      },
      "source": [
        "In this part, you should incorporate the word distance information to BasicCorefModel described in the HW. The below code structure provided to you is exactly the same as BasicCorefModel, your job is to add code into both __init__() and scorer() functions as you see fit.\n",
        "\n",
        "Hint: You might consider initialize distance embedding in __init__() function, then concatenate the original embedding and the corresponding distance embedding in scorer(). \n",
        "\n",
        "After implementing this, run the sanity check, test_distance(), provided to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04w8HtOHzm25"
      },
      "source": [
        "class DistanceCorefModel(nn.Module):\n",
        "\t\"\"\" The code provided here starts out as just a copy of BasicCorefModel \"\"\"\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(DistanceCorefModel, self).__init__()\n",
        "\t\tself.vocab=vocab\n",
        "\n",
        "\t\t# initialize distance embeddings as identity matrix\t\n",
        "\t\tself.distance_embeddings = nn.Embedding.from_pretrained(torch.eye(10,10))\n",
        "\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\t\t_, embedding_size= embeddings.shape\n",
        "\t\tself.hidden_dim=50\n",
        "\n",
        "\t\t# update input size to reflect concatenated distance embedding of one-hot vector of size d=10\n",
        "\t\tself.input_size= 2 * embedding_size + 10\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh = nn.Tanh()\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tdevice = torch.device(\"cpu\")\n",
        "\t\tthis_batch_size=len(batch_x)\n",
        "\t\tnum_ants=len(batch_x[0])\n",
        "\t\t#print(num_ants)\n",
        "\t\t# get representations for mentions\n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m):\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size]\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\t\t\n",
        "\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\t\n",
        "\t\tantAbsDistance = []\n",
        "\t\tfor idx,mention in enumerate(batch_m):\n",
        "\t\t\tdists = []\n",
        "\t\t\tfor ant_id, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tdis = mention.absolute_end_idx - ant.absolute_end_idx\n",
        "\t\t\t\tif dis <= 0: \n",
        "\t\t\t\t\tantDist = 0\n",
        "\t\t\t\telif dis <= 1:\n",
        "\t\t\t\t\tantDist = 1\n",
        "\t\t\t\telif dis <= 2:\n",
        "\t\t\t\t\tantDist = 2\n",
        "\t\t\t\telif dis <= 3:\n",
        "\t\t\t\t\tantDist = 3\n",
        "\t\t\t\telif dis <= 4:\n",
        "\t\t\t\t\tantDist = 4\n",
        "\t\t\t\telif dis <= 7:\n",
        "\t\t\t\t\tantDist = 5\n",
        "\t\t\t\telif dis <= 15:\n",
        "\t\t\t\t\tantDist =6\n",
        "\t\t\t\telif dis <= 31:\n",
        "\t\t\t\t\tantDist = 7\n",
        "\t\t\t\telif dis <= 63:\n",
        "\t\t\t\t\tantDist = 8\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tantDist = 9\n",
        "\t\t\t\tdists.append(antDist)\n",
        "\t\t\tantAbsDistance.append(dists)\n",
        "\n",
        "\t\tdistance_abs_embeddings = self.distance_embeddings(torch.LongTensor(antAbsDistance).to(device))\n",
        "\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size].\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, (embedding_size + embedding_size + distance_embedding_size)]\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings, distance_abs_embeddings], 2)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\n",
        "\t\t# Let's fix the score for starting a new entity to be 0; all of the other scores for candidate antecedents will end up \n",
        "\t\t# being relative to that.\n",
        "\n",
        "\t\t# [this_batch_size, 1]\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\n",
        "\t\treturn preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iym9YsLOROHV"
      },
      "source": [
        "def test_distance(model):\n",
        "  batch_x=[]\n",
        "  maxLen=100\n",
        "  for i in range(maxLen):\n",
        "    mention=Mention(i, \"testdoc\", i, i+1, 0, 1, [\"John\", \"Smith\", \"is\", \"a\", \"person\"], model.vocab)\n",
        "    batch_x.append(mention)\n",
        "\n",
        "  mention=Mention(maxLen, \"testdoc\", maxLen, maxLen, 0, 0, [\"He\", \"is\", \"a\", \"person\"], model.vocab)\n",
        "\n",
        "  preds=model.scorer([batch_x], [mention])\n",
        "  preds=preds.detach().cpu().numpy()[0]\n",
        "  spearman, _= spearmanr(preds, np.arange(len(preds)))\n",
        "  print(\"Distance check: %.3f\" % spearman)\n",
        "  with open(\"distance_predictions.txt\", \"w\", encoding=\"utf-8\") as out:\n",
        "    out.write(' '.join([\"%.5f\" % x for x in preds]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwVahwYxRVo-",
        "outputId": "3e19f1d2-d572-4b17-c609-e5f55b50f63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "set_seed(159)\n",
        "model=DistanceCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "print (\"Training DistanceCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)\n",
        "test_distance(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training DistanceCorefModel\n",
            "loss: 38142.238, B3 F: 0.771, unique entities: 27516, num mentions: 29597\n",
            "loss: 31295.287, B3 F: 0.792, unique entities: 25643, num mentions: 29597\n",
            "loss: 27499.352, B3 F: 0.801, unique entities: 25037, num mentions: 29597\n",
            "loss: 24978.295, B3 F: 0.806, unique entities: 24524, num mentions: 29597\n",
            "loss: 23457.592, B3 F: 0.812, unique entities: 24143, num mentions: 29597\n",
            "loss: 22521.248, B3 F: 0.815, unique entities: 23976, num mentions: 29597\n",
            "loss: 21872.807, B3 F: 0.816, unique entities: 23865, num mentions: 29597\n",
            "loss: 21376.531, B3 F: 0.817, unique entities: 23796, num mentions: 29597\n",
            "loss: 20969.732, B3 F: 0.818, unique entities: 23712, num mentions: 29597\n",
            "loss: 20621.184, B3 F: 0.819, unique entities: 23643, num mentions: 29597\n",
            "Distance check: 0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPy6ps0sSED9"
      },
      "source": [
        "### **Part 2.2 Design a fancier model**\n",
        "Here comes the fun part! After completing DistanceCorefModel, you have certain degree of familiarity with the model architecture. In the section, you will be implementing a fancier model using any features you'd like. Feel free to make changes to the architecture you see fit.\n",
        "\n",
        "Submit this notebook to gradescope and a writeup file \"fancymodel.txt\" describing your model and the features you use.\n",
        "**Your code must implement exactly what you describe in your writeup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41WHfSAo6Ms-"
      },
      "source": [
        "In my fancy model implementation (more detailed explanation in writeup)\n",
        "\n",
        "*   I used a 10K dictionary instead of 50K\n",
        "*   I used 200-d representation of word embeddings instead of 50-d\n",
        "*   included similarity between the tokens in word's sentence and in the mention's sentence (cosine similarity)\n",
        "*   used distance between two words in terms of absolute index\n",
        "*   used parallelism between two words' positions in their respective sentences, using bins for the first 2 words, the first 5 words, the first 7 words, the first 10 words and further away.\n",
        "*   I also tried to included information about gender agreement (male, female, neutral) and number agreement (singular plural) but I couldn't find an already existing dictionary to download to use with the mentions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT_vFHagClgn",
        "outputId": "5ba09aa2-aaad-4664-f6ae-3435ba3a44ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "embeddingFile = \"glove.6B.200d.txt\"\n",
        "trainFile = \"train.conll\"\n",
        "devFile = \"dev.conll\"\n",
        "all_sents, all_ents=read_conll(trainFile)\t\n",
        "dev_all_sents, dev_all_ents = read_conll(devFile)\n",
        "embeddings, vocab = load_embeddings(embeddingFile, 100000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_embedding_dim: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tbubxvkzqoo"
      },
      "source": [
        "class FancyCorefModel(nn.Module):\n",
        "\n",
        "\tdef __init__(self, vocab, embeddings):\n",
        "\t\tsuper(FancyCorefModel, self).__init__()\n",
        "\t\tself.vocab=vocab\n",
        "\n",
        "\t\t# initialize distance embeddings as identity matrix\t\n",
        "\t\tself.distance_embeddings = nn.Embedding.from_pretrained(torch.eye(10,10))\n",
        "\t\tself.number_embeddings = nn.Embedding.from_pretrained(torch.eye(2,2))\n",
        "\t\tself.gender_embeddings = nn.Embedding.from_pretrained(torch.eye(3,3))\n",
        "\t\tself.local_positional_embeddings = nn.Embedding.from_pretrained(torch.eye(5,5))\n",
        "\t\tself.context_similarity_embeddings = nn.Embedding.from_pretrained(torch.eye(2,2))\n",
        "\t\n",
        "\t\tself.embeddings = nn.Embedding.from_pretrained(embeddings)\n",
        "\t\t_, embedding_size= embeddings.shape\n",
        "\t\tself.hidden_dim=50\n",
        "\n",
        "\t\t# update input size to reflect concatenated distance embedding of one-hot vector of size d=10\n",
        "\t\tself.input_size= 2 * embedding_size + 17\n",
        "\t\tself.W1 = nn.Linear(self.input_size, self.hidden_dim)\n",
        "\t\tself.tanh=nn.Tanh()\n",
        "\t\tself.W2 = nn.Linear(self.hidden_dim, 1)\t\n",
        "\n",
        "\tdef scorer(self, batch_x, batch_m):\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tInput: a batch containing:\n",
        "\t\t\t-- batch_m [list of Mention objects]: mention to resolve.  batch_m[i] contains a single Mention\n",
        "\t\t\t-- batch_x [list of [list of Mention objects]]: candidate antecedents. batch_x[i] contains a list of candidate antecedents for mention batch_m[i]\n",
        "\t\tEach input batch is batched to contain the same number of candidate antecedents\n",
        "\t\tOutput: numpy matrix [batch_size, number_of_antecedents + 1, 1] containing scores for all antecedents\n",
        "\t\t\t-- for j < number_of_antecedents, output[i,j] contains the score of batch_x[i][j] being the correct antecedent for batch_m[i] \n",
        "\t\t\t-- for j == number_of_antecedents, output[i,j] = 0 (the score for batch_m[i] being linked to no antecedent)\n",
        "\n",
        "\t\t\"\"\"\n",
        "\t\tdevice = torch.device(\"cpu\")\n",
        "\t\tthis_batch_size=len(batch_x)\n",
        "\t\tnum_ants=len(batch_x[0])\n",
        "\t\t#print(num_ants)\n",
        "\t\t# get representations for mentions\n",
        "\t\tlastWordID=[]\n",
        "\n",
        "\t\tfor idx, mention in enumerate(batch_m):\n",
        "\t\t\tlastWordID.append(mention.sentence_ids[mention.sentence_end_idx])\n",
        "\n",
        "\t\t# [this_batch_size, 1, embedding_size]\n",
        "\t\tmention_LW_embeddings=self.embeddings(torch.LongTensor(lastWordID).to(device)).unsqueeze(1)\n",
        "\t\t\n",
        "\n",
        "\t\t# get representations for antecedents\n",
        "\t\tantLastWords=[]\n",
        "\t\tgenderWords = []\n",
        "\t\tnumberWords = []\n",
        "\t\t\n",
        "\t\tfor idx in range(len(batch_x)):\n",
        "\t\t\tantWords=[]\n",
        "\t\t\tfor ant_idx, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tantWords.append(ant.sentence_ids[ant.sentence_end_idx])\n",
        "\n",
        "\t\t\tantLastWords.append(antWords)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tantecedent_LW_embeddings=self.embeddings(torch.LongTensor(antLastWords).to(device))\n",
        "\t\n",
        "\t\tantAbsDistance = []\n",
        "\t\tantLocalDistance = []\n",
        "\t\tsimilarity = []\n",
        "\t\tfor idx,mention in enumerate(batch_m):\n",
        "\t\t\tdists = []\n",
        "\t\t\tlocs = []\n",
        "\t\t\tsims = []\n",
        "\t\t\tsent_mention = mention.sentence_ids\n",
        "\n",
        "\t\t\t\n",
        "\t\t\tfor ant_id, ant in enumerate(batch_x[idx]):\n",
        "\t\t\t\tdis = mention.absolute_end_idx - ant.absolute_end_idx\n",
        "\t\t\t\tlocal = abs(mention.sentence_start_idx - ant.sentence_start_idx)\n",
        "\t\t\t\tant_mention = ant.sentence_ids\n",
        "\t\t\t\tfor i in range(len(ant_mention)):\n",
        "\t\t\t\t\tif ant_mention[i] == []:\n",
        "\t\t\t\t\t\tant_mention[i] = -1\n",
        "\n",
        "\t\t\t\tmagn = (np.linalg.norm(sent_mention)*np.linalg.norm(ant_mention))\n",
        "\t\t\t\tif len(sent_mention) != len(ant_mention):\n",
        "\t\t\t\t\t#print(np.dot(ant_mention,sent_mention)/magn)\n",
        "\t\t\t\t\t#sims.append(np.dot(ant_mention,sent_mention)/magn)\n",
        "\t\t\t\t#else:\n",
        "\t\t\t\t\tif len(sent_mention) > len(ant_mention):\n",
        "\t\t\t\t\t\tdiff = len(sent_mention) - len(ant_mention)\n",
        "\t\t\t\t\t\tant_mention += [-1] * diff\n",
        "\t\t\t\t\t\t#print(np.dot(ant_mention,sent_mention)/magn)\n",
        "\t\t\t\t\t\t#sims.append(np.dot(ant_mention,sent_mention)/magn)\n",
        "\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tdiff = len(ant_mention) - len(sent_mention)\n",
        "\t\t\t\t\t\tsent_mention += [-1] * diff\n",
        "\t\t\t\t\t\t#print(np.dot(ant_mention,sent_mention)/magn)\n",
        "\t\t\t\t\t\t#sims.append(np.dot(ant_mention,sent_mention)/magn)\n",
        "\t\t\t\tval = np.dot(ant_mention,sent_mention)/magn\n",
        "\t\t\t\tif val <= 0.5:\n",
        "\t\t\t\t\tsims.append(0)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsims.append(1)\n",
        "\n",
        "\t\t\t\tif local <= 1:\n",
        "\t\t\t\t\tlocs.append(0)\n",
        "\t\t\t\telif local <= 4:\n",
        "\t\t\t\t\tlocs.append(1)\n",
        "\t\t\t\telif local <= 7:\n",
        "\t\t\t\t\tlocs.append(2)\n",
        "\t\t\t\telif local <= 10:\n",
        "\t\t\t\t\tlocs.append(3)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tlocs.append(4)\n",
        "\t\t\t\n",
        "\t\t\t\tif dis <= 0: \n",
        "\t\t\t\t\tantDist = 0\n",
        "\t\t\t\telif dis <= 1:\n",
        "\t\t\t\t\tantDist = 1\n",
        "\t\t\t\telif dis <= 2:\n",
        "\t\t\t\t\tantDist = 2\n",
        "\t\t\t\telif dis <= 3:\n",
        "\t\t\t\t\tantDist = 3\n",
        "\t\t\t\telif dis <= 4:\n",
        "\t\t\t\t\tantDist = 4\n",
        "\t\t\t\telif dis <= 7:\n",
        "\t\t\t\t\tantDist = 5\n",
        "\t\t\t\telif dis <= 15:\n",
        "\t\t\t\t\tantDist =6\n",
        "\t\t\t\telif dis <= 31:\n",
        "\t\t\t\t\tantDist = 7\n",
        "\t\t\t\telif dis <= 63:\n",
        "\t\t\t\t\tantDist = 8\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tantDist = 9\n",
        "\t\t\t\tdists.append(antDist)\n",
        "\t\t\tantAbsDistance.append(dists)\n",
        "\t\t\tantLocalDistance.append(locs)\n",
        "\t\t\tsimilarity.append(sims)\n",
        "\n",
        "\t\tdistance_abs_embeddings = self.distance_embeddings(torch.LongTensor(antAbsDistance).to(device))\n",
        "\t\tdistance_local_embeddings = self.local_positional_embeddings(torch.LongTensor(antLocalDistance).to(device))\n",
        "\t\tsimilarity_embeddings = self.context_similarity_embeddings(torch.tensor(similarity, dtype=torch.long).to(device))\n",
        "\t\n",
        "\t\t# We want to generate a score for each antecedent for each mention. However,\n",
        "\t\t# mention_LW_embeddings is [this_batch_size, 1, embedding_size] while,\n",
        "\t\t# antecedent_LW_embeddings is [this_batch_size, num_ants, embedding_size].\n",
        "\t\t# So let's make a bunch of copies of mention_LW_embeddings (one for each of its candidate antecedents)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, embedding_size]\n",
        "\t\tmention_LW_embeddings_copies=mention_LW_embeddings.expand_as(antecedent_LW_embeddings)\n",
        "\t\t# Now that they're the same size, we can concatenate them together into one big matrix\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, (embedding_size + embedding_size + distance_embedding_size)]\n",
        "\t\tall_features=torch.cat([mention_LW_embeddings_copies, antecedent_LW_embeddings, distance_abs_embeddings, distance_local_embeddings, similarity_embeddings], 2)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants, 1]\n",
        "\t\tpreds=self.W2(self.tanh(self.W1(all_features))).squeeze(-1)\n",
        "\n",
        "\t\t# Let's fix the score for starting a new entity to be 0; all of the other scores for candidate antecedents will end up \n",
        "\t\t# being relative to that.\n",
        "\n",
        "\t\t# [this_batch_size, 1]\n",
        "\t\tzeros=torch.FloatTensor(np.zeros((this_batch_size, 1))).to(device)\n",
        "\n",
        "\t\t# [this_batch_size, num_ants + 1, 1]\t\t\n",
        "\t\tpreds=torch.cat((preds, zeros), 1)\n",
        "\n",
        "\t\treturn preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uqdJ0085XoO",
        "outputId": "4b4f06ca-e384-4599-b41f-bd9587364327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "model=FancyCorefModel(vocab, embeddings)\n",
        "model=model.to(device)\n",
        "\n",
        "print (\"Training FancyCorefModel\")\n",
        "train(X, Y, M, train_truth, dev_X, dev_Y, dev_M, dev_truth, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training FancyCorefModel\n",
            "loss: 35771.641, B3 F: 0.787, unique entities: 25934, num mentions: 29597\n",
            "loss: 29107.641, B3 F: 0.804, unique entities: 24805, num mentions: 29597\n",
            "loss: 25350.598, B3 F: 0.814, unique entities: 24395, num mentions: 29597\n",
            "loss: 22846.283, B3 F: 0.820, unique entities: 24134, num mentions: 29597\n",
            "loss: 21188.838, B3 F: 0.823, unique entities: 23927, num mentions: 29597\n",
            "loss: 19990.572, B3 F: 0.825, unique entities: 23734, num mentions: 29597\n",
            "loss: 19059.873, B3 F: 0.826, unique entities: 23568, num mentions: 29597\n",
            "loss: 18303.123, B3 F: 0.826, unique entities: 23423, num mentions: 29597\n",
            "loss: 17672.068, B3 F: 0.827, unique entities: 23226, num mentions: 29597\n",
            "loss: 17130.100, B3 F: 0.827, unique entities: 23096, num mentions: 29597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu73DIyWAEM_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}